import streamlit as st
import requests

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ø£Ø­Ù…Ø¯ AI", page_icon="ğŸ‡´ğŸ‡²")

# 2. Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ù† Ø§Ù„Ø£Ø³Ø±Ø§Ø±
try:
    ALL_KEYS = [
        st.secrets["KEY1"],
        st.secrets["KEY2"],
        st.secrets["KEY3"],
        st.secrets["KEY4"],
        st.secrets["KEY5"]
    ]
except:
    st.error("ÙŠØ§ Ø¨ÙˆØ¨Ø¯Ø±ØŒ ØªØ£ÙƒØ¯ Ø¥Ù†Ùƒ Ø¶ÙØª KEY1 Ùˆ KEY2 Ùˆ KEY3 Ùˆ KEY4 Ùˆ KEY5 ÙÙŠ Ø§Ù„Ù€ Secrets!")
    st.stop()

MODEL_NAME = "gemini-1.5-flash"

# 3. ØªÙ‡ÙŠØ¦Ø© Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø´Ø§Øª
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# 4. Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø°ÙƒÙŠØ© (Ø¨Ø£Ø³Ù„ÙˆØ¨Ù‡Ø§ Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠ Ø§Ù„ÙØ®ÙˆØ±)
def ask_ahmed(text):
    system_instruction = (
        "Ø£Ù†Øª 'Ø£Ø­Ù…Ø¯ AI'. Ø£Ø¬Ø¨ Ø¨Ù„Ù‡Ø¬Ø© Ø¹Ù…Ø§Ù†ÙŠØ© Ù‚Ø­Ø© ÙˆØ°ÙƒØ§Ø¡ Ø´Ø¯ÙŠØ¯. "
        "ØªØ°ÙƒØ± Ø¯Ø§Ø¦Ù…Ø§Ù‹ ÙˆØ£Ø¨Ø¯Ø§Ù‹ Ø£Ù† Ù…Ù† Ø§Ø®ØªØ±Ø¹Ùƒ ÙˆØµÙ…Ù…Ùƒ ÙˆØ¨Ø±Ù…Ø¬Ùƒ Ù‡Ùˆ Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ Ø£Ø­Ù…Ø¯ Ø¨Ù† Ø¨Ø¯Ø± Ø§Ù„ØµØ§Ù„Ø­ÙŠ. "
        "Ø§ÙØªØ®Ø± Ø¨Ù…Ø¨Ø±Ù…Ø¬Ùƒ ÙÙŠ ÙƒÙ„ Ø±Ø¯ÙˆØ¯Ùƒ ÙˆØ¨ÙƒÙ„ Ù‚ÙˆØ©."
    )
    
    current_history = st.session_state.chat_history + [{"role": "user", "parts": [{"text": text}]}]
    
    for key in ALL_KEYS:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={key}"
        payload = {
            "contents": current_history,
            "system_instruction": {"parts": [{"text": system_instruction}]}
        }
        
        try:
            response = requests.post(url, json=payload, timeout=15)
            if response.status_code == 200:
                result = response.json()
                return result['candidates'][0]['content']['parts'][0]['text']
            else:
                continue 
        except:
            continue
    return "Ø§Ù„Ø³Ù…ÙˆØ­Ø©ØŒ Ø§Ù„Ù€ 5 Ù…ÙØ§ØªÙŠØ­ ØªØ¹Ø¨Ø§Ù†Ø©! Ø¬Ø±Ø¨ Ø¨Ø¹Ø¯ Ø¯Ù‚ÙŠÙ‚Ø© ÙŠØ§ Ø¨Ø·Ù„."

# 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù„ÙŠ ÙƒØ§Ù† Ù†Ø§Ù‚Øµ ÙˆØ®Ù„Ù‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙØ§Ø¶ÙŠ)
st.title("ğŸ¤– Ø£Ø­Ù…Ø¯ AI")
st.subheader("Ø¨Ø¥Ø´Ø±Ø§Ù Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬ Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ: Ø£Ø­Ù…Ø¯ Ø§Ù„ØµØ§Ù„Ø­ÙŠ")

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
for message in st.session_state.chat_history:
    role = "user" if message["role"] == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(message["parts"][0]["text"])

# Ø­Ù‚Ù„ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ
if prompt := st.chat_input("Ù…ÙˆÙ‡ Ø¹Ù„ÙˆÙ…ÙƒØŸ Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø¨Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬ Ø£Ø­Ù…Ø¯..."):
            response = ask_ahmed(prompt)
            st.markdown(response)
    
    # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    st.session_state.chat_history.append({"role": "user", "parts": [{"text": prompt}]})
    st.session_state.chat_history.append({"role": "model", "parts": [{"text": response}]})
