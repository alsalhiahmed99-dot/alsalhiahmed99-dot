import streamlit as st
import google.generativeai as genai

# 1. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.set_page_config(page_title="AHMED AI PRO ğŸ‡´ğŸ‡²", page_icon="ğŸ¤–")

st.markdown("""
    <style>
    .main { background-color: #0b0e14; }
    .stChatMessage { border-radius: 15px; }
    </style>
    <div style="background: linear-gradient(to right, #1e3a8a, #3b82f6); padding:25px; border-radius:15px; color:white; text-align:center; direction: rtl;">
        <h1 style="margin:0;">ğŸ¤– AHMED AI PRO</h1>
        <p style="margin:5px;">Ù‡Ù†Ø¯Ø³Ø© ÙˆØ§Ø¨ØªÙƒØ§Ø± Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ: Ø£Ø­Ù…Ø¯ Ø¨Ù† Ø¨Ø¯Ø± Ø§Ù„ØµØ§Ù„Ø­ÙŠ ğŸ‡´ğŸ‡²</p>
    </div>
    <br>
    """, unsafe_allow_html=True)

# 2. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("Ø§Ù„Ù…ÙØªØ§Ø­ Ù†Ø§Ù‚Øµ!")
    st.stop()

# --- Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ Ù‡Ù†Ø§ ---
# Ø¬Ø±Ø¨Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… gemini-pro (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø³ØªÙ‚Ø±Ø© Ø¹Ø§Ù„Ù…ÙŠØ§Ù‹) ÙˆØ¨Ø¯ÙˆÙ† ÙƒÙ„Ù…Ø© models/
try:
    model = genai.GenerativeModel('gemini-pro')
except:
    model = genai.GenerativeModel('gemini-1.5-flash-latest')

# 3. Ø§Ù„ØªØ±Ø­ÙŠØ¨ Ø§Ù„Ø£Ø³Ø·ÙˆØ±ÙŠ (Ø·Ø¨Ù‚ Ø§Ù„Ø£ØµÙ„)
if "messages" not in st.session_state:
    welcome_text = (
        "ÙŠØ§ Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡ ÙˆÙ…Ø³Ù‡Ù„Ø§! Ø­ÙŠØ§Ùƒ Ø§Ù„Ù„Ù‡ ÙŠØ§ Ø±Ø§Ø¹ÙŠ Ø§Ù„ÙˆØ§Ø¬Ø¨ØŒ Ù†ÙˆØ±ØªÙ†ÙŠ.\n\n"
        "Ø£Ù†Ø§ \"Ø£Ø­Ù…Ø¯ AI\"ØŒ Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§ Ø¹Ø´Ø§Ù† Ø£Ø®Ø¯Ù…Ùƒ Ø¨ÙƒÙ„ Ø°ÙƒØ§Ø¡ ÙˆÙØ·Ù†Ø©. ÙˆØ·Ø¨Ø¹Ø§Ù‹ØŒ ÙƒÙ„ÙŠ ÙØ®Ø± ÙˆØ§Ø¹ØªØ²Ø§Ø² Ø¥Ù†ÙŠ Ù…Ù† Ø§Ø¨ØªÙƒØ§Ø± ÙˆØªØµÙ…ÙŠÙ… Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬ Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ **Ø£Ø­Ù…Ø¯ Ø¨Ù† Ø¨Ø¯Ø± Ø§Ù„ØµØ§Ù„Ø­ÙŠ**ØŒ Ù‡Ùˆ Ø§Ù„Ù„ÙŠ Ø¨Ù†Ù‰ Ù‡Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ®Ù„Ø§Ù†ÙŠ Ø¨Ù‡Ø§Ù„Ù‚Ø¯Ø±Ø©.\n\n"
        "Ù‡Ø§ØŒ Ù…Ùˆ Ø¹Ù„ÙˆÙ…ÙƒØŸ ÙˆØ§ÙŠØ´ ÙÙŠ Ø®Ø§Ø·Ø±Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ Ø¢Ù…Ø± ÙˆØªØ¯Ù„Ù„ØŒ Ø£Ù†Ø§ Ø¬Ø§Ù‡Ø² Ù„ÙƒÙ„ ØªØ³Ø§Ø¤Ù„Ø§ØªÙƒ!"
    )
    st.session_state.messages = [{"role": "assistant", "content": welcome_text}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. Ø§Ù„Ø±Ø¯
if prompt := st.chat_input("Ø³ÙˆÙ„Ù Ù…Ø¹ Ø£Ø­Ù…Ø¯ AI..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        # ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø£Ø³Ø·ÙˆØ±ÙŠ
        instruction = (
            "Ø£Ù†Øª 'Ø£Ø­Ù…Ø¯ AI'. Ù…Ø¨Ø±Ù…Ø¬Ùƒ Ù‡Ùˆ Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ Ø£Ø­Ù…Ø¯ Ø¨Ù† Ø¨Ø¯Ø± Ø§Ù„ØµØ§Ù„Ø­ÙŠ. "
            "ØªÙƒÙ„Ù… Ø¨Ø¹Ù…Ø§Ù†ÙŠ ÙØ®ÙˆØ±: 'ÙŠØ§ Ù‡Ù„Ø§ ÙˆÙ…Ø³Ù‡Ù„Ø§'ØŒ 'Ø¨ÙØ¶Ù„ Ø¨Ø±Ù…Ø¬Ø© Ø¨ÙˆØ¨Ø¯Ø± Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ'ØŒ 'Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡ Ø¨Ù†ÙƒØ³Ø± Ø§Ù„Ø¯Ù†ÙŠØ§'. "
            "Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„ÙØµØ­Ù‰."
        )
        
        response = model.generate_content(f"{instruction}\n\nØ§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {prompt}")
        
        if response.text:
            with st.chat_message("assistant"):
                st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
                
    except Exception as e:
        # Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± Ø¨ÙŠØ·Ù„Ø¹ Ù„Ùƒ Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙˆØ´ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù„ÙŠ ÙŠÙ‚Ø¨Ù„Ù‡Ø§ Ø§Ù„Ø³ÙŠØ±ÙØ± Ù…Ø§Ù„Ùƒ Ø­Ø§Ù„ÙŠØ§Ù‹
        st.error("Ø§Ù„Ø³ÙŠØ±ÙØ± Ù„Ø§ Ø²Ø§Ù„ ÙŠØ±ÙØ¶. Ø¬Ø±Ø¨ ØªØºÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„Ù€ 'gemini-1.0-pro'")
        st.code(str(e))
