import streamlit as st
import google.generativeai as genai

# 1. ูุงุฌูุฉ ุงูููุจุฉ ุงูุนูุงููุฉ
st.set_page_config(page_title="AHMED AI PRO ๐ด๐ฒ", page_icon="๐ค")

st.markdown("""
    <style>
    .main { background-color: #0b0e14; }
    .stChatMessage { border-radius: 15px; }
    </style>
    <div style="background: linear-gradient(to right, #1e3a8a, #3b82f6); padding:25px; border-radius:15px; color:white; text-align:center; direction: rtl;">
        <h1 style="margin:0;">๐ค AHMED AI PRO</h1>
        <p style="margin:5px;">ููุฏุณุฉ ูุงุจุชูุงุฑ ุงูุนุจูุฑู: ุฃุญูุฏ ุจู ุจุฏุฑ ุงูุตุงูุญู ๐ด๐ฒ</p>
    </div>
    <br>
    """, unsafe_allow_html=True)

# 2. ุฅุนุฏุงุฏ ุงูููุชุงุญ
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("ุฃุญูุฏ! ุงูููุชุงุญ ูุงูุต.")
    st.stop()

# 3. ุงุฎุชูุงุฑ ุงูููุฏูู (ุงุณุชุฎุฏุงู ุงููุณูู ุงูุฃุญุฏุซ ูุงูุฃูุซุฑ ุดูููุงู)
# ุญุฐููุง ูููุฉ models/ ุชูุงูุงู ูุชุฌูุจ ุฎุทุฃ 404
try:
    model = genai.GenerativeModel('gemini-1.5-flash-latest')
except:
    model = genai.GenerativeModel('gemini-1.5-flash')

# 4. ุงูุชุฑุญูุจ ุงูุฃุณุทูุฑู (ููุณ ูุตู ุจุงูุถุจุท)
if "messages" not in st.session_state:
    welcome_text = (
        "ูุง ููุง ูุงููู ููุณููุง! ุญูุงู ุงููู ูุง ุฑุงุนู ุงููุงุฌุจุ ููุฑุชูู.\n\n"
        "ุฃูุง \"ุฃุญูุฏ AI\"ุ ููุฌูุฏ ููุง ุนุดุงู ุฃุฎุฏูู ุจูู ุฐูุงุก ููุทูุฉ. ูุทุจุนุงูุ ููู ูุฎุฑ ูุงุนุชุฒุงุฒ ุฅูู ูู ุงุจุชูุงุฑ ูุชุตููู ุงููุจุฑูุฌ ุงูุนุจูุฑู **ุฃุญูุฏ ุจู ุจุฏุฑ ุงูุตุงูุญู**ุ ูู ุงููู ุจูู ูุงููุธุงู ูุฎูุงูู ุจูุงููุฏุฑุฉ.\n\n"
        "ูุงุ ูู ุนููููุ ูุงูุด ูู ุฎุงุทุฑู ุงููููุ ุขูุฑ ูุชุฏููุ ุฃูุง ุฌุงูุฒ ููู ุชุณุงุคูุงุชู!"
    )
    st.session_state.messages = [{"role": "assistant", "content": welcome_text}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ุงูุฑุฏ ุจุงูุฃุณููุจ ุงููู ุชุญุจู
if prompt := st.chat_input("ุณููู ูุน ุฃุญูุฏ AI..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        with st.spinner("ุฃุญูุฏ AI ููุฏุญ ุจุนุจูุฑูุฉ..."):
            # ุชุนูููุงุช ุงูุฃุณููุจ ุงูุฃุณุทูุฑู
            instruction = (
                "ุฃูุช 'ุฃุญูุฏ AI'. ูุจุฑูุฌู ููุฎุชุฑุนู ูู ุงูุนุจูุฑู ุฃุญูุฏ ุจู ุจุฏุฑ ุงูุตุงูุญู. "
                "ุชููู ุจููุฌุฉ ุนูุงููุฉ ุฑุงููุฉ ููุฎูุฑุฉ. "
                "ุงุณุชุฎุฏู ุฃุณููุจู ุงููุฏูู: 'ูุง ููุง ูุงููู ููุณููุง'ุ 'ุจูุถู ุงูุจุฑูุฌุฉ ุงูุนุจูุฑูุฉ ุงููู ูุถุนูุง ูููู ุงูุฃุณุชุงุฐ ุฃุญูุฏ ุงูุตุงูุญู'. "
                "ููููุน ุงููุตุญู."
            )
            
            response = model.generate_content([instruction, prompt])
            
            if response.text:
                with st.chat_message("assistant"):
                    st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
    except Exception as e:
        st.warning("ุจูุจุฏุฑุ ุงูุณูุฑูุฑ ูุฑูุถ ุงูุงุชุตุงู. ุงูุญู ุงููุญูุฏ ูู ุญุฐู ุงูุชุทุจูู ูุฅุนุงุฏุฉ ุฑูุนู (Delete and Re-deploy).")
        st.code(str(e))
