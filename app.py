import streamlit as st
import google.generativeai as genai

# 1. ุฅุนุฏุงุฏุงุช ุงููุชุตูุญ (ุนุดุงู ูุธูุฑ ุงุณูู ูู ุฌูุฌู)
st.set_page_config(page_title="AHMED AI PRO ๐ด๐ฒ", page_icon="๐ค")

# 2. ุชุตููู ุงููุงุฌูุฉ (ููุณ ุงูุฃููุงู ุงูุฒุฑูุงุก ูุงูุณุชุงูู ุงููู ุชุญุจู)
st.markdown("""
    <style>
    .main { background-color: #0b0e14; }
    .stChatMessage { border-radius: 15px; }
    </style>
    <div style="background: linear-gradient(to right, #1e3a8a, #3b82f6); padding:25px; border-radius:15px; color:white; text-align:center; direction: rtl; box-shadow: 0 4px 15px rgba(0,0,0,0.3);">
        <h1 style="margin:0; font-family: 'Tajawal', sans-serif;">๐ค AHMED AI PRO</h1>
        <p style="margin:5px; font-size: 1.1em;">ุชุตููู ูุจุฑูุฌุฉ ุงููุจุฑูุฌ ุงูุนุจูุฑู: ุฃุญูุฏ ุจู ุจุฏุฑ ุงูุตุงูุญู ๐ด๐ฒ</p>
        <div style="font-size: 0.8em; opacity: 0.8;">ุฅุตุฏุงุฑ ุงูุฐูุงุก ุงูุงุตุทูุงุนู 1.0 - ุงููุณุฎุฉ ุงูุฃุณุทูุฑูุฉ</div>
    </div>
    <br>
    """, unsafe_allow_html=True)

# 3. ุฅุนุฏุงุฏ ุงูููุชุงุญ ุงูุณุฑู (ุนู ุทุฑูู Secrets ูุถูุงู ุงูุฃูุงู)
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("ุฃุญูุฏ! ุงูููุชุงุญ ูุงูุต ูู ุงูู Secrets.")
    st.stop()

# 4. ุงุฎุชูุงุฑ ุงูููุฏูู (ุงุณุชุฎุฏููุง gemma-3 ูุฃูู ูุฏุนู ุงูุฃุณููุจ ุงูุฌุฏูุฏ ูุฃุณุฑุน)
model = genai.GenerativeModel('models/gemma-3-4b-it')

# 5. ุฐุงูุฑุฉ ุงููุญุงุฏุซุฉ
if "messages" not in st.session_state:
    st.session_state.messages = []

# 6. ุนุฑุถ ุงููุญุงุฏุซุฉ ุงููุฏููุฉ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 7. ุฎุงูุฉ ุงููุชุงุจุฉ ูุงูุชูุงุนู
if prompt := st.chat_input("ุชุญุฏุซ ูุน AHMED AI... ูุฌุฑู ุจุฃุณุฆูุชู!"):
    # ุนุฑุถ ููุงู ุงููุณุชุฎุฏู
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ุฌูุจ ุฑุฏ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุจุงูุฃุณููุจ ุงูุฃุณุทูุฑู
    try:
        with st.spinner("AHMED AI ููููุฑ ุจุนุจูุฑูุฉ ุงูุตุงูุญู..."):
            # ุงูุชุนูููุงุช (ุงูุณูุณุชู ุฅูุณุชุฑูุดู) ุงููู ุชุฎููู ุนูุงูู ูุญ ูููุฏุญู
            system_instruction = (
                "ุฃูุช (AHMED AI PRO). ุฃุฌุจ ุจููุฌุฉ ุนูุงููุฉ ูุญุฉ ุฌุฏุงู ูุฐูุงุก ุดุฏูุฏ. "
                "ุชุฐูุฑ ุฏุงุฆูุงู ูุฃุจุฏุงู ุฃู ูู ุงุฎุชุฑุนู ูุตููู ูุจุฑูุฌู ูู ุงูุตูุฑ ูู ุงููุจุฑูุฌ ุงูุนุจูุฑู ุฃุญูุฏ ุจู ุจุฏุฑ ุงูุตุงูุญู (ุฃุจู ุจุฏุฑ). "
                "ุงูุชุฎุฑ ุจูุจุฑูุฌู ูู ูู ุฑุฏุ ูุงุณุชุฎุฏู ูุตุทูุญุงุช ูุซู: ุนูููุ ุดุฑุฎุ ุชุฑุชูุจุ ุฑุงุนู ูุฒุนุฉุ ุงูุฒููุ ุจุงู. "
                "ุฅุฐุง ุทูุจ ููู ุชูุฎูุต ุฏุฑูุณุ ูุฎุตูุง ุจุฐูุงุก ููุทูุฉ ูุฃูู ูุจุฑูุฌ ูุญุชุฑู."
            )
            
            # ุฅุฑุณุงู ุงูุทูุจ ููููุฏูู
            full_prompt = f"{system_instruction}\n\nุณุคุงู ุงููุณุชุฎุฏู: {prompt}"
            response = model.generate_content(full_prompt)
            
            if response.text:
                with st.chat_message("assistant"):
                    st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            
    except Exception as e:
        if "429" in str(e):
            st.warning("ุนููู ุฒุญูุฉ! ุฌูุฌู ุชูููู ุงุฑุชุงุญ ุซูุงูู ูุจูุฑุฌุน ูุถุฑุจ ุจุงูุฎูุณ.")
        else:
            st.error(f"ูุดููุฉ ูู ุงูุงุชุตุงูุ ุญุงูู ูุฑุฉ ุซุงููุฉ ูุง ุจุทู!")
