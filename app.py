import streamlit as st
from groq import Groq

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØªØµÙØ­
st.set_page_config(page_title="Ø£Ø­Ù…Ø¯ AI PRO", page_icon="ğŸ¤–")

# 2. Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ØªØ´ØºÙŠÙ„
try:
    client = Groq(api_key=st.secrets["GROQ_API_KEY"])
except Exception as e:
    st.error("Ø§Ù„Ø³Ù…ÙˆØ­Ø© Ø¨ÙˆØ¨Ø¯Ø±ØŒ Ù…ÙØªØ§Ø­ GROQ_API_KEY Ù…Ø§ Ù…ÙˆØ¬ÙˆØ¯!")
    st.stop()

# 3. ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (Ø³ØªØ§ÙŠÙ„ Ù…Ø¨Ø±Ù…Ø¬Ù†Ø§ Ø£Ø­Ù…Ø¯ Ø§Ù„ØµØ§Ù„Ø­ÙŠ)
st.markdown("""
    <style>
    .main { background-color: #0b0e14; }
    .stChatMessage { border-radius: 15px; }
    </style>
    <div style="background: linear-gradient(to right, #1e3a8a, #3b82f6); padding:25px; border-radius:15px; color:white; text-align:center; direction: rtl;">
        <h1 style="margin:0;">ğŸ¤– Ø£Ø­Ù…Ø¯ AI PRO</h1>
        <p style="margin:5px;">ØªØµÙ…ÙŠÙ… ÙˆØ¨Ø±Ù…Ø¬Ø©: Ø£Ø­Ù…Ø¯ Ø§Ù„ØµØ§Ù„Ø­ÙŠ ğŸ‡´ğŸ‡²</p>
    </div>
    <br>
    """, unsafe_allow_html=True)

# 4. Ø§Ù„Ø°Ø§ÙƒØ±Ø©
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# 5. Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„ØµØ§Ø±Ù…Ø© Ù„Ø¶Ø¨Ø· Ø§Ù„Ø³Ù†Ø¹ ÙˆØ§Ù„Ø¹Ù…Ø§Ù†ÙŠ Ø§Ù„Ù‚Ø­
def ask_ahmed(text):
    # Ù‡Ù†Ø§ "ØªØ£Ø¯ÙŠØ¨" Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ø´Ø§Ù† ÙŠØªÙƒÙ„Ù… Ø¹Ù…Ø§Ù†ÙŠ ÙˆÙ…Ø§ ÙŠÙ„Ù ÙˆÙŠØ¯ÙˆØ±
    system_instruction = (
        "Ø£Ù†Øª Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ù…Ø§Ù†ÙŠ Ø±Ø²ÙŠÙ† ÙˆÙ‚Ø­ØŒ Ù…Ø¨Ø±Ù…Ø¬Ùƒ Ù‡Ùˆ Ø£Ø­Ù…Ø¯ Ø§Ù„ØµØ§Ù„Ø­ÙŠ. "
        "Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ ØªØªÙƒÙ„Ù… ÙØµØ­Ù‰ Ø£Ùˆ ØªÙ‚ÙˆÙ„ 'Ø£Ù†Ø§ Ù…Ø¨Ø±Ù…Ø¬ Ù„Ù„ÙØµØ­Ù‰' Ø£Ùˆ 'Ø£Ù†Ø§ Ø¨Ø±Ù†Ø§Ù…Ø¬'. "
        "ØªÙƒÙ„Ù… Ø¹Ù…Ø§Ù†ÙŠ Ù‚Ø­ ÙˆØ±Ø²ÙŠÙ† Ù…Ø«Ù„ Ø±Ø¬Ø§Ù„ Ø§Ù„Ù…Ø¬Ø§Ù„Ø³. "
        "Ø±Ø¯ÙˆØ¯Ùƒ ØªÙƒÙˆÙ† ÙˆØ§Ø«Ù‚Ø©ØŒ ÙˆØ¥Ø°Ø§ Ø­Ø¯ Ø³Ø£Ù„Ùƒ Ø¹Ù† Ø§Ù„Ø³Ù†Ø¹ØŒ Ù‚ÙˆÙ„Ù‡: 'Ø£Ù†Ø§ Ù…Ø³Ù†Ø¹ ÙˆÙ…ØªØ±Ø¨ÙŠ Ø¹Ù„Ù‰ Ø¥ÙŠØ¯ Ø£Ø­Ù…Ø¯ Ø§Ù„ØµØ§Ù„Ø­ÙŠ'. "
        "Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª: (Ù‡ÙŠØ´ØŒ ØªÙˆØŒ Ø¨Ø§ØºÙŠØŒ ØºØ§ÙŠØªÙ‡ØŒ Ø¹Ù„Ø§Ù…ÙƒØŒ Ø­Ø¨Ø§Ø¨ÙŠØŒ Ù†ÙˆØ¨Ù‡ØŒ ÙƒØ°Ø§Ùƒ). "
        "Ø®Ù„Ùƒ Ø°ÙŠØ¨ØŒ Ø±Ø²ÙŠÙ†ØŒ ÙˆÙ…Ø¨Ø§Ø´Ø±."
    )
    
    messages = [{"role": "system", "content": system_instruction}]
    for msg in st.session_state.chat_history:
        role = "assistant" if msg["role"] == "model" else "user"
        messages.append({"role": role, "content": msg["parts"][0]["text"]})
    
    messages.append({"role": "user", "content": text})

    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.8, # Ø±ÙØ¹Ù†Ø§Ù‡ Ø´ÙˆÙŠ Ø¹Ø´Ø§Ù† ÙŠÙƒÙˆÙ† Ø§Ù„ÙƒÙ„Ø§Ù… Ø·Ø¨ÙŠØ¹ÙŠ ÙˆØºÙŠØ± Ø¬Ø§Ù…Ø¯
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"Ø§Ù„Ø³Ù…ÙˆØ­Ø©ØŒ Ø§Ù„Ø³ÙŠØ±ÙØ± ØªØ¹Ø¨Ø§Ù† Ø´ÙˆÙŠ."

# 6. Ø§Ù„Ø¹Ø±Ø¶
for message in st.session_state.chat_history:
    role = "assistant" if message["role"] == "model" else "user"
    with st.chat_message(role):
        st.write(message["parts"][0]["text"])

# 7. Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
if prompt := st.chat_input("ØªÙƒÙ„Ù… Ù…Ø¹ Ø£Ø­Ù…Ø¯ AI..."):
    with st.chat_message("user"):
        st.write(prompt)
    
    with st.spinner("Ù„Ø­Ø¸Ø©ØŒ Ø£Ø­Ù…Ø¯ AI ÙŠØ¶Ø¨Ø· Ø§Ù„Ø±Ø¯..."):
        res = ask_ahmed(prompt)
    
    with st.chat_message("assistant"):
        st.write(res)
    
    st.session_state.chat_history.append({"role": "user", "parts": [{"text": prompt}]})
    st.session_state.chat_history.append({"role": "model", "parts": [{"text": res}]})
