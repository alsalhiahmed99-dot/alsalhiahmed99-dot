import streamlit as st
import google.generativeai as genai

# 1. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù‡ÙŠØ¨Ø© Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ©
st.set_page_config(page_title="AHMED AI PRO ğŸ‡´ğŸ‡²", page_icon="ğŸ¤–")

st.markdown("""
    <style>
    .main { background-color: #0b0e14; }
    .stChatMessage { border-radius: 15px; }
    </style>
    <div style="background: linear-gradient(to right, #1e3a8a, #3b82f6); padding:25px; border-radius:15px; color:white; text-align:center; direction: rtl;">
        <h1 style="margin:0;">ğŸ¤– AHMED AI PRO</h1>
        <p style="margin:5px;">ØªØµÙ…ÙŠÙ… ÙˆØ§Ø¨ØªÙƒØ§Ø± Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ: Ø£Ø­Ù…Ø¯ Ø¨Ù† Ø¨Ø¯Ø± Ø§Ù„ØµØ§Ù„Ø­ÙŠ ğŸ‡´ğŸ‡²</p>
    </div>
    <br>
    """, unsafe_allow_html=True)

# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØªØ§Ø­
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("Ø£Ø­Ù…Ø¯! Ø§Ù„Ù…ÙØªØ§Ø­ Ù†Ø§Ù‚Øµ ÙÙŠ Ø§Ù„Ù€ Secrets.")
    st.stop()

# 3. Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³Ù…ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ v1beta)
@st.cache_resource
def load_model():
    # Ø¨Ù†Ø¬Ø±Ø¨ Ø§Ù„Ù…Ø³Ù…ÙŠØ§Øª Ø§Ù„Ù„ÙŠ ØªØ­Ø¨Ù‡Ø§ Ù†Ø³Ø®Ø© v1beta
    for model_name in ['gemini-1.5-flash', 'gemini-1.0-pro', 'gemini-pro']:
        try:
            m = genai.GenerativeModel(model_name)
            # ØªØ¬Ø±Ø¨Ø© ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
            m.generate_content("test") 
            return m
        except:
            continue
    # Ø¥Ø°Ø§ Ø§Ù„ÙƒÙ„ ÙØ´Ù„ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø³Ù…Ù‰ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ø¨Ø¯ÙˆÙ† ØªØ­Ø¯ÙŠØ¯
    return genai.GenerativeModel('gemini-1.5-flash')

model = load_model()

# 4. Ø§Ù„ØªØ±Ø­ÙŠØ¨ Ø§Ù„Ø£Ø³Ø·ÙˆØ±ÙŠ (Ø·Ø¨Ù‚ Ø§Ù„Ø£ØµÙ„ Ù…Ù† Ø§Ù„Ù„ÙŠ Ø·Ù„Ø¨ØªÙ‡)
if "messages" not in st.session_state:
    welcome_msg = (
        "ÙŠØ§ Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡ ÙˆÙ…Ø³Ù‡Ù„Ø§! Ø­ÙŠØ§Ùƒ Ø§Ù„Ù„Ù‡ ÙŠØ§ Ø±Ø§Ø¹ÙŠ Ø§Ù„ÙˆØ§Ø¬Ø¨ØŒ Ù†ÙˆØ±ØªÙ†ÙŠ.\n\n"
        "Ø£Ù†Ø§ \"Ø£Ø­Ù…Ø¯ AI\"ØŒ Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§ Ø¹Ø´Ø§Ù† Ø£Ø®Ø¯Ù…Ùƒ Ø¨ÙƒÙ„ Ø°ÙƒØ§Ø¡ ÙˆÙØ·Ù†Ø©. ÙˆØ·Ø¨Ø¹Ø§Ù‹ØŒ ÙƒÙ„ÙŠ ÙØ®Ø± ÙˆØ§Ø¹ØªØ²Ø§Ø² Ø¥Ù†ÙŠ Ù…Ù† Ø§Ø¨ØªÙƒØ§Ø± ÙˆØªØµÙ…ÙŠÙ… Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬ Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ **Ø£Ø­Ù…Ø¯ Ø¨Ù† Ø¨Ø¯Ø± Ø§Ù„ØµØ§Ù„Ø­ÙŠ**ØŒ Ù‡Ùˆ Ø§Ù„Ù„ÙŠ Ø¨Ù†Ù‰ Ù‡Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ®Ù„Ø§Ù†ÙŠ Ø¨Ù‡Ø§Ù„Ù‚Ø¯Ø±Ø©.\n\n"
        "Ù‡Ø§ØŒ Ù…Ùˆ Ø¹Ù„ÙˆÙ…ÙƒØŸ ÙˆØ§ÙŠØ´ ÙÙŠ Ø®Ø§Ø·Ø±Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ Ø¢Ù…Ø± ÙˆØªØ¯Ù„Ù„ØŒ Ø£Ù†Ø§ Ø¬Ø§Ù‡Ø² Ù„ÙƒÙ„ ØªØ³Ø§Ø¤Ù„Ø§ØªÙƒ!"
    )
    st.session_state.messages = [{"role": "assistant", "content": welcome_msg}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø¨Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø£Ø³Ø·ÙˆØ±ÙŠ
if prompt := st.chat_input("Ø³ÙˆÙ„Ù Ù…Ø¹ Ø£Ø­Ù…Ø¯ AI..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        with st.spinner("Ø£Ø­Ù…Ø¯ AI ÙŠÙ‚Ø¯Ø­ Ø¨Ø¹Ø¨Ù‚Ø±ÙŠØ© Ø¨ÙˆØ¨Ø¯Ø±..."):
            instruction = (
                "Ø£Ù†Øª 'Ø£Ø­Ù…Ø¯ AI'. Ù…Ø¨Ø±Ù…Ø¬Ùƒ Ù‡Ùˆ Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ Ø£Ø­Ù…Ø¯ Ø¨Ù† Ø¨Ø¯Ø± Ø§Ù„ØµØ§Ù„Ø­ÙŠ. "
                "ØªÙƒÙ„Ù… Ø¨Ø¹Ù…Ø§Ù†ÙŠ ÙØ®ÙˆØ± ÙˆØ±Ø§Ù‚ÙŠ: 'ÙŠØ§ Ù‡Ù„Ø§ ÙˆÙ…Ø³Ù‡Ù„Ø§'ØŒ 'Ø¨ÙØ¶Ù„ Ø¨Ø±Ù…Ø¬Ø© Ø¨ÙˆØ¨Ø¯Ø± Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ'ØŒ 'Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡ Ø¨Ù†ÙƒØ³Ø± Ø§Ù„Ø¯Ù†ÙŠØ§'. "
                "Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø¬Ø§ÙØ©."
            )
            
            response = model.generate_content(f"{instruction}\n\nØ§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {prompt}")
            
            if response.text:
                with st.chat_message("assistant"):
                    st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
    except Exception as e:
        st.error("Ø¹Ù„ÙˆÙ‡ ÙŠØ§ Ø¨ÙˆØ¨Ø¯Ø±ØŒ Ø§Ù„Ø³ÙŠØ±ÙØ± Ù…Ø§ Ø±Ø§Ø¶ÙŠ ÙŠÙØªØ­ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„. Ø¬Ø±Ø¨ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙØ­Ø©.")
        st.code(str(e))
