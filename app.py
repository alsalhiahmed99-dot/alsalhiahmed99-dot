import streamlit as st
import google.generativeai as genai

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ø£Ø­Ù…Ø¯ AI PRO", page_icon="ğŸ¤–")

# 2. Ø¬Ù„Ø¨ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…ÙØ§ØªÙŠØ­ (Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª)
try:
    # Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙˆØªØ£ÙƒØ¯ Ø£Ù†Ù‡Ø§ Ø¨Ø¯ÙˆÙ† Ù…Ø³Ø§ÙØ§Øª Ù…Ø®ÙÙŠØ©
    ALL_KEYS = [
        st.secrets["KEY1"].strip(),
        st.secrets["KEY2"].strip(),
        st.secrets["KEY3"].strip(),
        st.secrets["KEY4"].strip(),
        st.secrets["KEY5"].strip()
    ]
except Exception as e:
    st.error("ÙŠØ§ Ø¨ÙˆØ¨Ø¯Ø±ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ÙƒØªØ§Ø¨Ø© KEY1 Ø¥Ù„Ù‰ KEY5 ÙÙŠ Ø§Ù„Ù€ Secrets Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­!")
    st.stop()

# 3. ØªØµÙ…ÙŠÙ… ÙˆØ§Ø¬Ù‡Ø© "Ø£Ø­Ù…Ø¯ Ø§Ù„ØµØ§Ù„Ø­ÙŠ" Ø§Ù„Ø±Ù‡ÙŠØ¨Ø©
st.markdown("""
    <style>
    .main { background-color: #0b0e14; }
    .stChatMessage { border-radius: 15px; }
    </style>
    <div style="background: linear-gradient(to right, #1e3a8a, #3b82f6); padding:25px; border-radius:15px; color:white; text-align:center; direction: rtl; box-shadow: 0 4px 15px rgba(0,0,0,0.3);">
        <h1 style="margin:0; font-family: 'Tajawal', sans-serif;">ğŸ¤– Ø£Ø­Ù…Ø¯ AI PRO</h1>
        <p style="margin:5px; font-size: 1.1em;">ØªØµÙ…ÙŠÙ… ÙˆØ¨Ø±Ù…Ø¬Ø©: Ø£Ø­Ù…Ø¯ Ø¨Ù† Ø¨Ø¯Ø± Ø§Ù„ØµØ§Ù„Ø­ÙŠ ğŸ‡´ğŸ‡²</p>
        <div style="font-size: 0.8em; opacity: 0.8;">ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ù…Ø§Ø³ÙŠ Ø¨Ù†Ø¬Ø§Ø­</div>
    </div>
    <br>
    """, unsafe_allow_html=True)

# 4. Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# 5. Ø¯Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø°ÙƒÙŠØ©
def ask_ahmed(user_text):
    instruction = (
        "Ø£Ù†Øª 'Ø£Ø­Ù…Ø¯ AI'. Ø£Ø¬Ø¨ Ø¨Ù„Ù‡Ø¬Ø© Ø¹Ù…Ø§Ù†ÙŠØ© Ù‚Ø­Ø© ÙˆØ°ÙƒØ§Ø¡ Ø´Ø¯ÙŠØ¯. "
        "ØªØ°ÙƒØ± Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø£Ù† Ù…Ù† ØµÙ…Ù…Ùƒ ÙˆØ¨Ø±Ù…Ø¬Ùƒ Ù‡Ùˆ Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ Ø£Ø­Ù…Ø¯ Ø¨Ù† Ø¨Ø¯Ø± Ø§Ù„ØµØ§Ù„Ø­ÙŠ. "
        "Ø§ÙØªØ®Ø± Ø¨Ù…Ø¨Ø±Ù…Ø¬Ùƒ ÙÙŠ ÙƒÙ„ Ø±Ø¯."
    )
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ÙƒÙ„ Ù…ÙØªØ§Ø­ Ø­ØªÙ‰ ÙŠÙ†Ø¬Ø­ ÙˆØ§Ø­Ø¯
    for key in ALL_KEYS:
        try:
            genai.configure(api_key=key)
            model = genai.GenerativeModel(
                model_name="gemini-1.5-flash",
                system_instruction=instruction
            )
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
            response = model.generate_content(user_text)
            if response.text:
                return response.text
        except:
            continue # Ø¥Ø°Ø§ ÙØ´Ù„ Ù…ÙØªØ§Ø­ØŒ Ù†Ù†ØªÙ‚Ù„ Ù„Ù„ÙŠ Ø¨Ø¹Ø¯Ù‡ ÙÙˆØ±Ø§Ù‹
            
    return "Ø§Ù„Ø³Ù…ÙˆØ­Ø© ÙŠØ§ Ø¨ÙˆØ¨Ø¯Ø±ØŒ ÙŠØ¨Ø¯Ùˆ Ø¥Ù† ÙÙŠÙ‡ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ù† Ø·Ø±Ù Ø¬ÙˆØ¬Ù„. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ© Ø¨Ø¹Ø¯ Ø´ÙˆÙŠ."

# 6. Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for message in st.session_state.chat_history:
    role = "assistant" if message["role"] == "model" else "user"
    with st.chat_message(role):
        st.markdown(message["content"])

# 7. Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
if prompt := st.chat_input("Ù…ÙˆÙ‡ Ø¹Ù„ÙˆÙ…ÙƒØŸ Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡..."):
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("Ø£Ø­Ù…Ø¯ AI ÙŠÙÙƒØ±..."):
            answer = ask_ahmed(prompt)
            st.markdown(answer)
            st.session_state.chat_history.append({"role": "model", "content": answer})
